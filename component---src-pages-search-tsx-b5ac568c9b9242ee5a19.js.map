{"version":3,"file":"component---src-pages-search-tsx-b5ac568c9b9242ee5a19.js","mappings":"yJAAA,MAAMA,EAAWC,IACPA,GAA2C,IAAhCC,OAAOC,KAAKF,GAASG,OAG7BC,EAAeA,CAACJ,EAAkBK,KAC7C,GAAIN,EAAQC,GACV,OAAO,KAET,MAAMM,EAAUN,EAAQO,QAAQF,GAEhC,OAAKC,EAGEE,KAAKC,MAAMH,GAFT,IAEiB,EAGfI,EAAaA,CAACV,EAAkBK,EAAaM,IACpDZ,EAAQC,GACH,KAEFA,EAAQY,QAAQP,EAAKG,KAAKK,UAAUF,ICpBhCG,EAA4B,oBAANC,OAAyBA,OAAOD,kBAAeE,EACrEC,EAA8B,oBAANF,OAAyBA,OAAOE,oBAAiBD,ECIzEE,ICAyBC,EAAAA,EAAAA,IAAQT,EAAYI,IAClBK,EAAAA,EAAAA,IAAQf,EAAcU,IDDtBK,EAAAA,EAAAA,IAAQT,EAAYO,IAC/CG,GAA6BD,EAAAA,EAAAA,IAAQf,EAAca,GEH1DI,EAAsB,qCCc5B,MAdyBC,KACvB,MAAMC,GDEiBC,ECFe,EDG/BJ,EAA8BC,EAAmB,WAAaG,GAD9CA,MCDvB,MAAM,EAACC,EAAM,EAACC,IAAYC,EAAAA,EAAAA,UAAiBJ,GACrCK,GAAWC,EAAAA,EAAAA,QAAOJ,GAClBK,GAAgBC,EAAAA,EAAAA,cAAY,IAAML,GAAUM,GAASA,EAAO,KAAI,IAOtE,OALAC,EAAAA,EAAAA,YAAU,KACRL,EAASM,QAAUT,EDCdP,EAA4BG,EAAmB,SCAnCI,EAAM,GACtB,CAACA,IAEG,CAACA,EAAOG,EAAUE,EAAc,C,qCCHzC,IATwBK,KACtBF,EAAAA,EAAAA,YAAU,KACRlB,OAAOqB,iBAAiB,SAAUD,EAAU,CAAEE,SAAS,IAChD,KACLtB,OAAOuB,oBAAoB,SAAUH,EAAS,IAE/C,GAAG,C,iKC2CJI,EAAmC,WACrC,SAASA,IAAuB,CAmBhC,OAjBaA,EAAoBC,UAK1BC,YAAc,SAAqBC,GAIxC,IAHA,IAAIC,EAAiB,GACjBC,EAAS,GAEJC,EAAI,EAAG1C,EAASuC,EAAMvC,OAAQ0C,EAAI1C,IAAU0C,EACnDD,GAAUF,EAAMI,OAAOD,GACvBF,EAAeI,KAAKH,GAGtB,OAAOD,CACT,EAEOJ,CACT,CArBuC,GA4CnCS,EAAkC,WACpC,SAASA,IAAsB,CAW/B,OATaA,EAAmBR,UAKzBS,SAAW,SAAkBC,GAClC,OAAOA,EAAOA,EAAKC,oBAAoBC,OAAS,EAClD,EAEOJ,CACT,CAbsC,GAsBtC,SAASK,EAAoBC,EAAQC,GACnCA,EAAOA,GAAQ,GAIf,IAFA,IAAIC,EADJF,EAASA,GAAU,CAAC,EAGXT,EAAI,EAAGA,EAAIU,EAAKpD,OAAQ0C,IAG/B,GAAa,OAFbW,EAAQA,EAAMD,EAAKV,KAGjB,OAAO,KAIX,OAAOW,CACT,CAKA,IAAIC,EAAgC,WAClC,SAASA,EAAiBC,GACxBC,KAAKC,cAAgBF,EACrBC,KAAKE,iBAAmB,CAAC,EACzBF,KAAKG,UAAY,CAAC,CACpB,CAMA,IAAIC,EAASN,EAAiBjB,UA+H9B,OA7HAuB,EAAOC,cAAgB,SAAuBtB,EAAOuB,EAAKC,GACxDP,KAAKE,iBAAmB,CAAC,EAEzB,IACIM,EADAC,EAAWT,KAAKG,UAGW,iBAApBM,EAAS1B,GAClB0B,EAAS1B,GAASyB,EAAa,CAC7BE,wBAAyB,EACzBC,qBAAsB,EACtBC,QAAS,CAAC,IAGZJ,EAAaC,EAAS1B,IACX4B,uBAGb,IAAIE,EAASL,EAAWI,QAEG,iBAAhBC,EAAOP,IAChBE,EAAWE,0BACXG,EAAOP,GAAO,CACZQ,UAAWP,EACXQ,qBAAsB,IAGxBF,EAAOP,GAAKS,sBAEhB,EAMAX,EAAOY,OAAS,SAAgBC,EAAQC,GAGtC,IAFA,IAAIC,EAAmB,CAAC,EAEfjC,EAAI,EAAGkC,EAAYH,EAAOzE,OAAQ0C,EAAIkC,EAAWlC,IAAK,CAC7D,IAAIH,EAAQkC,EAAO/B,GACfmC,EAAgBrB,KAAKG,UAAUpB,GAEnC,IAAKsC,EACH,MAAO,GAGT,GAAU,IAANnC,EAGF,IAFA,IAESoC,EAAI,EAAGC,GAFZhF,EAAOD,OAAOC,KAAK8E,EAAcT,UAENpE,OAAQ8E,EAAIC,EAASD,IAAK,CAEvDH,EADIb,EAAM/D,EAAK+E,IACSD,EAAcT,QAAQN,GAAKQ,SACrD,KAEA,KAAIvE,EAEJ,IAAS+E,EAAI,EAAGC,GAFZhF,EAAOD,OAAOC,KAAK4E,IAEQ3E,OAAQ8E,EAAIC,EAASD,IAAK,CACvD,IAAIhB,EAAM/D,EAAK+E,GAE2B,iBAA/BD,EAAcT,QAAQN,WACxBa,EAAiBb,EAE5B,CARwC,CAU5C,CAEA,IAAIkB,EAAY,GAEhB,IAAK,IAAIlB,KAAOa,EACdK,EAAUpC,KAAK+B,EAAiBb,IAGlC,IAAImB,EAAiBzB,KAAK0B,wBAG1B,OAAOF,EAAUG,MAAK,SAAUC,EAAWC,GACzC,OAAOJ,EAAeR,EAAQY,EAAWX,GAAUO,EAAeR,EAAQW,EAAWV,EACvF,GACF,EAEAd,EAAO0B,oBAAsB,WAC3B,IAAIrB,EAAWT,KAAKG,UAChB4B,EAAkB/B,KAAKE,iBAC3B,OAAO,SAAsBnB,EAAOyC,GAClC,IAAKO,EAAgBhD,GAAQ,CAC3B,IAAIiD,OAAmD,IAApBvB,EAAS1B,GAAyB0B,EAAS1B,GAAO2B,wBAA0B,EAC/GqB,EAAgBhD,GAAS,EAAIkD,KAAKC,IAAIV,EAAUhF,QAAU,EAAIwF,GAChE,CAEA,OAAOD,EAAgBhD,EACzB,CACF,EAEAqB,EAAOsB,sBAAwB,WAC7B,IAAIjB,EAAWT,KAAKG,UAChBJ,EAAeC,KAAKC,cAEpBkC,EAAenC,KAAK8B,sBAExB,OAAO,SAAwBb,EAAQmB,EAAUZ,GAG/C,IAFA,IAAIa,EAAQ,EAEHnD,EAAI,EAAGkC,EAAYH,EAAOzE,OAAQ0C,EAAIkC,IAAalC,EAAG,CAC7D,IAOIoB,EAPAvB,EAAQkC,EAAO/B,GACfoD,EAA2BH,EAAapD,EAAOyC,GAE/Cc,IAA6BC,MAC/BD,EAA2B,GAM3BhC,EADEP,aAAwByC,MACpBJ,GAAY1C,EAAoB0C,EAAUrC,GAE1CqC,GAAYA,EAASrC,GAI7BsC,SAD+C,IAApB5B,EAAS1B,SAAkE,IAAjC0B,EAAS1B,GAAO6B,QAAQN,GAAuBG,EAAS1B,GAAO6B,QAAQN,GAAKS,qBAAuB,GAC/IuB,CAC3B,CAEA,OAAOD,CACT,CACF,EAEOvC,CACT,CA3IoC,GAqNhC2C,EAAQ,qBAKRC,EAA+B,WACjC,SAASA,IAAmB,CAc5B,OAZaA,EAAgB7D,UAKtB8D,SAAW,SAAkBpD,GAClC,OAAOA,EAAKqD,MAAMH,GAAOI,QAAO,SAAUtD,GACxC,OAAOA,CACT,GAEF,EAEOmD,CACT,CAhBmC,GAwNnC,SAASI,EAAkBC,EAAQC,GACjC,IAAK,IAAI9D,EAAI,EAAGA,EAAI8D,EAAMxG,OAAQ0C,IAAK,CACrC,IAAI+D,EAAaD,EAAM9D,GACvB+D,EAAWC,WAAaD,EAAWC,aAAc,EACjDD,EAAWE,cAAe,EACtB,UAAWF,IAAYA,EAAWG,UAAW,GACjD9G,OAAO+G,eAAeN,EAAQE,EAAWvG,IAAKuG,EAChD,CACF,CAaA,IAAIK,EAAsB,WAUxB,SAASA,EAAOvD,GACd,IAAKA,EACH,MAAMwD,MAAM,6DAGdvD,KAAKC,cAAgBF,EAErBC,KAAKwD,eAAiB,IAAI5E,EAC1BoB,KAAKyD,aAAe,IAAI3D,EAAiBC,GACzCC,KAAK0D,WAAa,IAAIrE,EACtBW,KAAK2D,WAAa,IAAIjB,EACtB1C,KAAK4D,WAAa,GAClB5D,KAAK6D,kBAAoB,EAC3B,CAQA,IA1CoBC,EAAaC,EAAYC,EA0CzC5D,EAASkD,EAAOzE,UAuKpB,OAjKAuB,EAAO6D,YAAc,SAAqB7B,GACxCpC,KAAKkE,aAAa,CAAC9B,GACrB,EAOAhC,EAAO8D,aAAe,SAAsB1C,GAC1CxB,KAAK4D,WAAa5D,KAAK4D,WAAWO,OAAO3C,GACzCxB,KAAKoE,gBAAgB5C,EAAWxB,KAAK6D,kBACvC,EAQAzD,EAAOiE,SAAW,SAAkBC,GAClCtE,KAAK6D,kBAAkBzE,KAAKkF,GAE5BtE,KAAKoE,gBAAgBpE,KAAK4D,WAAY,CAACU,GACzC,EAQAlE,EAAOY,OAAS,SAAgBuD,GAC9B,IAAItD,EAASjB,KAAK2D,WAAWhB,SAAS3C,KAAK0D,WAAWpE,SAASiF,IAE/D,OAAOvE,KAAKyD,aAAazC,OAAOC,EAAQjB,KAAK4D,WAC/C,EAQAxD,EAAOgE,gBAAkB,SAAyB5C,EAAWqC,GAC3D7D,KAAKwE,cAAe,EAOpB,IANA,IAAIC,EAAgBzE,KAAKwD,eACrBkB,EAAY1E,KAAK0D,WACjBiB,EAAc3E,KAAKyD,aACnBmB,EAAY5E,KAAK2D,WACjB5D,EAAeC,KAAKC,cAEf4E,EAAK,EAAGC,EAAetD,EAAUhF,OAAQqI,EAAKC,EAAcD,IAAM,CACzE,IACIvE,EADAC,EAAMiB,EAAUqD,GAIlBvE,EADEP,aAAwByC,MACpB9C,EAAoBa,EAAKR,GAEzBQ,EAAIR,GAGZ,IAAK,IAAIgF,EAAM,EAAGC,EAAsBnB,EAAkBrH,OAAQuI,EAAMC,EAAqBD,IAAO,CAClG,IAAIE,EACAC,EAAkBrB,EAAkBkB,GAYxC,GAJkB,OALhBE,EADEC,aAA2B1C,MAChB9C,EAAoBa,EAAK2E,GAEzB3E,EAAI2E,KAG6B,iBAAfD,GAA2BA,EAAWE,WACrEF,EAAaA,EAAWE,YAGA,iBAAfF,EAGT,IAFA,IAAIG,EAAcR,EAAUjC,SAAS+B,EAAUpF,SAAS2F,IAE/CI,EAAM,EAAGC,EAAiBF,EAAY5I,OAAQ6I,EAAMC,EAAgBD,IAI3E,IAHA,IAAIE,EAAaH,EAAYC,GACzBrG,EAAiByF,EAAc3F,YAAYyG,GAEtCC,EAAM,EAAGC,EAAqBzG,EAAexC,OAAQgJ,EAAMC,EAAoBD,IAAO,CAC7F,IAAIE,EAAgB1G,EAAewG,GACnCb,EAAYtE,cAAcqF,EAAepF,EAAKC,EAChD,CAGN,CACF,CACF,EA3IoBuD,EA6IPR,GA7IoBS,EA6IZ,CAAC,CACpBrH,IAAK,gBACLiJ,IAAK,SAAa9F,GAChB,GAAIG,KAAKwE,aACP,MAAMjB,MAAM,qDAGdvD,KAAKwD,eAAiB3D,CACxB,EACA+F,IAAK,WACH,OAAO5F,KAAKwD,cACd,GAOC,CACD9G,IAAK,YACLiJ,IAAK,SAAa9F,GAChB,GAAIG,KAAKwE,aACP,MAAMjB,MAAM,iDAGdvD,KAAK0D,WAAa7D,CACpB,EACA+F,IAAK,WACH,OAAO5F,KAAK0D,UACd,GAOC,CACDhH,IAAK,cACLiJ,IAAK,SAAa9F,GAChB,GAAIG,KAAKwE,aACP,MAAMjB,MAAM,mDAGdvD,KAAKyD,aAAe5D,CACtB,EACA+F,IAAK,WACH,OAAO5F,KAAKyD,YACd,GAOC,CACD/G,IAAK,YACLiJ,IAAK,SAAa9F,GAChB,GAAIG,KAAKwE,aACP,MAAMjB,MAAM,iDAGdvD,KAAK2D,WAAa9D,CACpB,EACA+F,IAAK,WACH,OAAO5F,KAAK2D,UACd,MA7Mcb,EAAkBgB,EAAYjF,UAAWkF,GACrDC,GAAalB,EAAkBgB,EAAaE,GA+MzCV,CACT,CAvM0B,G,iCCnkBa,IAAAuC,EAAA,CAAAC,KAAA,SAAAC,OAAA,iDA6EvC,MAjEmBC,IAQmB,IAPpChJ,MACEiJ,MACEC,cACEC,SAAS,mBAAEC,OAIcJ,EAC/B,MAAM,OAAEK,IAAWC,EAAAA,EAAAA,MACb,KAAEtJ,GCjBoBuJ,MAC5B,MAAM,OAAEF,IAAWC,EAAAA,EAAAA,MACb,EAACE,EAAa,EAACC,IAAmBzI,EAAAA,EAAAA,UAAc,KAChD,kBAAE0I,IAAsBC,EAAAA,EAAAA,gBAAe,cAoBvCnF,GAAYoF,EAAAA,EAAAA,UAChB,IACEF,EAAkBG,MAAMC,KAAIjB,IAAA,IAAC,KAAEkB,GAAsBlB,EAAA,MAAM,CACzDmB,GAAID,EAAKC,GACTC,MAAOF,EAAKG,YAAYD,MACxBE,QAASJ,EAAKI,QACdC,KAAML,EAAKM,OAAOD,KAClBE,QAASP,EAAKQ,KAAKC,QAAQ,gBAAiB,IAC7C,KACH,CAACd,EAAkBG,QAGfY,GAAWb,EAAAA,EAAAA,UAAQ,IAAM,IAAItD,EAAO,OAAO,IAgBjD,OAdAmE,EAASpD,SAAS,SAClBoD,EAASpD,SAAS,WAClBoD,EAASpD,SAAS,WAClBoD,EAASvD,aAAa1C,IAEtBlD,EAAAA,EAAAA,YAAU,KACR,GAAI+H,EAAOqB,QAAX,CACE,MAAMC,EAASF,EAASzG,OAAOqF,EAAOqB,SACtCjB,EAAgBkB,EAElB,MACAlB,EAAgB,GAAG,GAClB,CAACgB,EAAUpB,EAAOqB,UAEd,CAAE1K,KAAMwJ,EAAc,EDlCZD,IACVzI,EAAOG,EAAUE,IAAiBR,EAAAA,EAAAA,KAEnCiK,GAAcxJ,EAAAA,EAAAA,cAAayJ,GACxBC,EAAAA,KAA0BD,GAChC,KAEHE,EAAAA,EAAAA,MAEAC,EAAAA,EAAAA,IAAe,KACb,MAAMH,EAAazK,OAAO6K,QAAU7K,OAAO8K,YACrCC,EAAeA,IAAMP,EAAYC,GAAcO,EAAAA,GAGrD,OAAOC,EAAAA,EAAAA,GAAMlK,EAAe,CAC1BmK,iBAAkBA,KAAOH,IACzBI,iBAAkBA,IAAMJ,KAJCnL,EAAKR,OAASyB,EAASM,QAAU6H,GAErDiC,EAGH,IAGN,MAAMG,GAAe5B,EAAAA,EAAAA,UAAQ,IACpB5J,EAAKyL,MAAM,EAAG3K,EAAQsI,IAC5B,CAACpJ,EAAMc,EAAOsI,IAEjB,OACEsC,EAAAA,EAAAA,IAAA,OAAAC,SAAA,EACEC,EAAAA,EAAAA,IAACC,EAAAA,GAAU,CACTC,QAAQ,SACRC,IAAGlD,EAID8C,SAED3L,EAAKR,OAAS,EAAC,IACR6J,EAAOqB,QAAO,YAAY1K,EAAKR,OAAM,kBACrC6J,EAAOqB,QAAO,yBAExBkB,EAAAA,EAAAA,IAACI,EAAAA,EAAQ,CAACC,MAAOT,MACb,C,uDEzEH,MAAMH,EAAQA,CACnBa,EAAYrD,KAER,IADJ,iBAAEyC,EAAmBA,MAAM,GAAK,iBAAEC,EAAmBA,MAAM,IAAM1C,EAEjE,IAAKqD,EACH,MAAM3F,MAAM,8BAGd,IAAI4F,GAAO,EAEX,MAAO,IACDA,EACK,MAGTA,GAAO,EACAC,uBAAsB,IACvBd,KACFa,GAAO,EACA,MAGLZ,KACFY,GAAO,EACAD,KAEF,OAEV,C","sources":["webpack://blog/./src/utils/storage/core.ts","webpack://blog/./src/utils/storage/browser.ts","webpack://blog/./src/utils/storage/sessionStorage.ts","webpack://blog/./src/utils/storage/localStorage.ts","webpack://blog/./src/utils/storage/index.ts","webpack://blog/./src/hooks/useRenderedCount.ts","webpack://blog/./src/hooks/useScrollEvent.ts","webpack://blog/../../node_modules/js-search/dist/esm/js-search.js","webpack://blog/./src/pages/search.tsx","webpack://blog/./src/hooks/useQueryPost.ts","webpack://blog/./src/utils/event-manager.ts"],"sourcesContent":["const isEmpty = (storage: Storage) => {\n  return !storage || Object.keys(storage).length === 0\n}\n\nexport const getValueFrom = (storage: Storage, key: string) => {\n  if (isEmpty(storage)) {\n    return null\n  }\n  const rawData = storage.getItem(key)\n\n  if (!rawData) {\n    return null\n  }\n  return JSON.parse(rawData)\n}\n\nexport const setValueTo = (storage: Storage, key: string, data: any) => {\n  if (isEmpty(storage)) {\n    return null\n  }\n  return storage.setItem(key, JSON.stringify(data))\n}\n","export const localStorage = typeof window !== `undefined` ? window.localStorage : undefined\nexport const sessionStorage = typeof window !== `undefined` ? window.sessionStorage : undefined\n","import { partial } from 'maeng-utils/utils'\n\nimport { setValueTo, getValueFrom } from './core'\nimport { sessionStorage } from './browser'\n\nexport const setValueToSessionStorage = partial(setValueTo, sessionStorage!)\nexport const getValueFromSessionStorage = partial(getValueFrom, sessionStorage!)\n","import { partial } from 'maeng-utils/utils'\n\nimport { setValueTo, getValueFrom } from './core'\nimport { localStorage } from './browser'\n\nexport const setValueToLocalStorage = partial(setValueTo, localStorage!)\nexport const getValueFromLocalStorage = partial(getValueFrom, localStorage!)\n","import { getValueFromLocalStorage, setValueToLocalStorage } from './localStorage'\nimport { getValueFromSessionStorage, setValueToSessionStorage } from './sessionStorage'\n\nconst SESSION_STORAGE_KEY = '__maeng_blog_session_storage_key__'\nconst LOCAL_STORAGE_KEY = '__maeng_blog_local_storage_key__'\n\nexport const getCount = (defaultValue: number) => {\n  return getValueFromSessionStorage(`${SESSION_STORAGE_KEY}/count`) || defaultValue\n}\n\nexport const setCount = (val: number) => {\n  return setValueToSessionStorage(`${SESSION_STORAGE_KEY}/count`, val)\n}\n\nexport const getData = () => {\n  return getValueFromLocalStorage(LOCAL_STORAGE_KEY)\n}\n\nexport const setData = (val: string) => {\n  return setValueToLocalStorage(LOCAL_STORAGE_KEY, val)\n}\n\nexport const getTheme = (defaultValue: string) => {\n  return getValueFromLocalStorage(`${LOCAL_STORAGE_KEY}/theme`) || defaultValue\n}\n\nexport const setTheme = (val: string) => {\n  return setValueToLocalStorage(`${LOCAL_STORAGE_KEY}/theme`, val)\n}\n","import { useState, useEffect, useRef, useCallback } from 'react'\nimport * as Storage from '@/utils/storage'\n\nconst useRenderedCount = () => {\n  const initialCount = Storage.getCount(1)\n  const [count, setCount] = useState<number>(initialCount)\n  const countRef = useRef(count)\n  const increaseCount = useCallback(() => setCount((prev) => prev + 1), [])\n\n  useEffect(() => {\n    countRef.current = count\n    Storage.setCount(count)\n  }, [count])\n\n  return [count, countRef, increaseCount] as const\n}\n\nexport default useRenderedCount\n","import { useEffect } from 'react'\n\nconst useScrollEvent = (onScroll: (e: Event) => void) => {\n  useEffect(() => {\n    window.addEventListener(`scroll`, onScroll, { passive: false })\n    return () => {\n      window.removeEventListener(`scroll`, onScroll)\n    }\n  }, [])\n}\n\nexport default useScrollEvent\n","/**\n * Indexes for all substring searches (e.g. the term \"cat\" is indexed as \"c\", \"ca\", \"cat\", \"a\", \"at\", and \"t\").\n */\nvar AllSubstringsIndexStrategy = /*#__PURE__*/function () {\n  function AllSubstringsIndexStrategy() {}\n\n  var _proto = AllSubstringsIndexStrategy.prototype;\n\n  /**\n   * @inheritDocs\n   */\n  _proto.expandToken = function expandToken(token) {\n    var expandedTokens = [];\n    var string;\n\n    for (var i = 0, length = token.length; i < length; ++i) {\n      string = '';\n\n      for (var j = i; j < length; ++j) {\n        string += token.charAt(j);\n        expandedTokens.push(string);\n      }\n    }\n\n    return expandedTokens;\n  };\n\n  return AllSubstringsIndexStrategy;\n}();\n\n/**\n * Indexes for exact word matches.\n */\nvar ExactWordIndexStrategy = /*#__PURE__*/function () {\n  function ExactWordIndexStrategy() {}\n\n  var _proto = ExactWordIndexStrategy.prototype;\n\n  /**\n   * @inheritDocs\n   */\n  _proto.expandToken = function expandToken(token) {\n    return token ? [token] : [];\n  };\n\n  return ExactWordIndexStrategy;\n}();\n\n/**\n * Indexes for prefix searches (e.g. the term \"cat\" is indexed as \"c\", \"ca\", and \"cat\" allowing prefix search lookups).\n */\nvar PrefixIndexStrategy = /*#__PURE__*/function () {\n  function PrefixIndexStrategy() {}\n\n  var _proto = PrefixIndexStrategy.prototype;\n\n  /**\n   * @inheritDocs\n   */\n  _proto.expandToken = function expandToken(token) {\n    var expandedTokens = [];\n    var string = '';\n\n    for (var i = 0, length = token.length; i < length; ++i) {\n      string += token.charAt(i);\n      expandedTokens.push(string);\n    }\n\n    return expandedTokens;\n  };\n\n  return PrefixIndexStrategy;\n}();\n\n/**\n * Enforces case-sensitive text matches.\n */\nvar CaseSensitiveSanitizer = /*#__PURE__*/function () {\n  function CaseSensitiveSanitizer() {}\n\n  var _proto = CaseSensitiveSanitizer.prototype;\n\n  /**\n   * @inheritDocs\n   */\n  _proto.sanitize = function sanitize(text) {\n    return text ? text.trim() : '';\n  };\n\n  return CaseSensitiveSanitizer;\n}();\n\n/**\n * Sanitizes text by converting to a locale-friendly lower-case version and triming leading and trailing whitespace.\n */\nvar LowerCaseSanitizer = /*#__PURE__*/function () {\n  function LowerCaseSanitizer() {}\n\n  var _proto = LowerCaseSanitizer.prototype;\n\n  /**\n   * @inheritDocs\n   */\n  _proto.sanitize = function sanitize(text) {\n    return text ? text.toLocaleLowerCase().trim() : '';\n  };\n\n  return LowerCaseSanitizer;\n}();\n\n/**\n * Find and return a nested object value.\n *\n * @param object to crawl\n * @param path Property path\n * @returns {any}\n */\nfunction getNestedFieldValue(object, path) {\n  path = path || [];\n  object = object || {};\n  var value = object; // walk down the property path\n\n  for (var i = 0; i < path.length; i++) {\n    value = value[path[i]];\n\n    if (value == null) {\n      return null;\n    }\n  }\n\n  return value;\n}\n\n/**\n * Search index capable of returning results matching a set of tokens and ranked according to TF-IDF.\n */\nvar TfIdfSearchIndex = /*#__PURE__*/function () {\n  function TfIdfSearchIndex(uidFieldName) {\n    this._uidFieldName = uidFieldName;\n    this._tokenToIdfCache = {};\n    this._tokenMap = {};\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = TfIdfSearchIndex.prototype;\n\n  _proto.indexDocument = function indexDocument(token, uid, doc) {\n    this._tokenToIdfCache = {}; // New index invalidates previous IDF caches\n\n    var tokenMap = this._tokenMap;\n    var tokenDatum;\n\n    if (typeof tokenMap[token] !== 'object') {\n      tokenMap[token] = tokenDatum = {\n        $numDocumentOccurrences: 0,\n        $totalNumOccurrences: 1,\n        $uidMap: {}\n      };\n    } else {\n      tokenDatum = tokenMap[token];\n      tokenDatum.$totalNumOccurrences++;\n    }\n\n    var uidMap = tokenDatum.$uidMap;\n\n    if (typeof uidMap[uid] !== 'object') {\n      tokenDatum.$numDocumentOccurrences++;\n      uidMap[uid] = {\n        $document: doc,\n        $numTokenOccurrences: 1\n      };\n    } else {\n      uidMap[uid].$numTokenOccurrences++;\n    }\n  }\n  /**\n   * @inheritDocs\n   */\n  ;\n\n  _proto.search = function search(tokens, corpus) {\n    var uidToDocumentMap = {};\n\n    for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n      var token = tokens[i];\n      var tokenMetadata = this._tokenMap[token]; // Short circuit if no matches were found for any given token.\n\n      if (!tokenMetadata) {\n        return [];\n      }\n\n      if (i === 0) {\n        var keys = Object.keys(tokenMetadata.$uidMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n          uidToDocumentMap[uid] = tokenMetadata.$uidMap[uid].$document;\n        }\n      } else {\n        var keys = Object.keys(uidToDocumentMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n\n          if (typeof tokenMetadata.$uidMap[uid] !== 'object') {\n            delete uidToDocumentMap[uid];\n          }\n        }\n      }\n    }\n\n    var documents = [];\n\n    for (var uid in uidToDocumentMap) {\n      documents.push(uidToDocumentMap[uid]);\n    }\n\n    var calculateTfIdf = this._createCalculateTfIdf(); // Return documents sorted by TF-IDF\n\n\n    return documents.sort(function (documentA, documentB) {\n      return calculateTfIdf(tokens, documentB, corpus) - calculateTfIdf(tokens, documentA, corpus);\n    });\n  };\n\n  _proto._createCalculateIdf = function _createCalculateIdf() {\n    var tokenMap = this._tokenMap;\n    var tokenToIdfCache = this._tokenToIdfCache;\n    return function calculateIdf(token, documents) {\n      if (!tokenToIdfCache[token]) {\n        var numDocumentsWithToken = typeof tokenMap[token] !== 'undefined' ? tokenMap[token].$numDocumentOccurrences : 0;\n        tokenToIdfCache[token] = 1 + Math.log(documents.length / (1 + numDocumentsWithToken));\n      }\n\n      return tokenToIdfCache[token];\n    };\n  };\n\n  _proto._createCalculateTfIdf = function _createCalculateTfIdf() {\n    var tokenMap = this._tokenMap;\n    var uidFieldName = this._uidFieldName;\n\n    var calculateIdf = this._createCalculateIdf();\n\n    return function calculateTfIdf(tokens, document, documents) {\n      var score = 0;\n\n      for (var i = 0, numTokens = tokens.length; i < numTokens; ++i) {\n        var token = tokens[i];\n        var inverseDocumentFrequency = calculateIdf(token, documents);\n\n        if (inverseDocumentFrequency === Infinity) {\n          inverseDocumentFrequency = 0;\n        }\n\n        var uid;\n\n        if (uidFieldName instanceof Array) {\n          uid = document && getNestedFieldValue(document, uidFieldName);\n        } else {\n          uid = document && document[uidFieldName];\n        }\n\n        var termFrequency = typeof tokenMap[token] !== 'undefined' && typeof tokenMap[token].$uidMap[uid] !== 'undefined' ? tokenMap[token].$uidMap[uid].$numTokenOccurrences : 0;\n        score += termFrequency * inverseDocumentFrequency;\n      }\n\n      return score;\n    };\n  };\n\n  return TfIdfSearchIndex;\n}();\n\n/**\n * Search index capable of returning results matching a set of tokens but without any meaningful rank or order.\n */\nvar UnorderedSearchIndex = /*#__PURE__*/function () {\n  function UnorderedSearchIndex() {\n    this._tokenToUidToDocumentMap = {};\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = UnorderedSearchIndex.prototype;\n\n  _proto.indexDocument = function indexDocument(token, uid, doc) {\n    if (typeof this._tokenToUidToDocumentMap[token] !== 'object') {\n      this._tokenToUidToDocumentMap[token] = {};\n    }\n\n    this._tokenToUidToDocumentMap[token][uid] = doc;\n  }\n  /**\n   * @inheritDocs\n   */\n  ;\n\n  _proto.search = function search(tokens, corpus) {\n    var intersectingDocumentMap = {};\n    var tokenToUidToDocumentMap = this._tokenToUidToDocumentMap;\n\n    for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n      var token = tokens[i];\n      var documentMap = tokenToUidToDocumentMap[token]; // Short circuit if no matches were found for any given token.\n\n      if (!documentMap) {\n        return [];\n      }\n\n      if (i === 0) {\n        var keys = Object.keys(documentMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n          intersectingDocumentMap[uid] = documentMap[uid];\n        }\n      } else {\n        var keys = Object.keys(intersectingDocumentMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n\n          if (typeof documentMap[uid] !== 'object') {\n            delete intersectingDocumentMap[uid];\n          }\n        }\n      }\n    }\n\n    var keys = Object.keys(intersectingDocumentMap);\n    var documents = [];\n\n    for (var i = 0, numKeys = keys.length; i < numKeys; i++) {\n      var uid = keys[i];\n      documents.push(intersectingDocumentMap[uid]);\n    }\n\n    return documents;\n  };\n\n  return UnorderedSearchIndex;\n}();\n\nvar REGEX = /[^a-zа-яё0-9\\-']+/i;\n/**\n * Simple tokenizer that splits strings on whitespace characters and returns an array of all non-empty substrings.\n */\n\nvar SimpleTokenizer = /*#__PURE__*/function () {\n  function SimpleTokenizer() {}\n\n  var _proto = SimpleTokenizer.prototype;\n\n  /**\n   * @inheritDocs\n   */\n  _proto.tokenize = function tokenize(text) {\n    return text.split(REGEX).filter(function (text) {\n      return text;\n    } // Filter empty tokens\n    );\n  };\n\n  return SimpleTokenizer;\n}();\n\n/**\n * Stemming is the process of reducing search tokens to their root (or stem) so that searches for different forms of a\n * word will match. For example \"search\", \"searching\" and \"searched\" are all reduced to the stem \"search\".\n *\n * <p>This stemming tokenizer converts tokens (words) to their stem forms before returning them. It requires an\n * external stemming function to be provided; for this purpose I recommend the NPM 'porter-stemmer' library.\n *\n * <p>For more information see http : //tartarus.org/~martin/PorterStemmer/\n */\nvar StemmingTokenizer = /*#__PURE__*/function () {\n  /**\n   * Constructor.\n   *\n   * @param stemmingFunction Function capable of accepting a word and returning its stem.\n   * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n   */\n  function StemmingTokenizer(stemmingFunction, decoratedTokenizer) {\n    this._stemmingFunction = stemmingFunction;\n    this._tokenizer = decoratedTokenizer;\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = StemmingTokenizer.prototype;\n\n  _proto.tokenize = function tokenize(text) {\n    return this._tokenizer.tokenize(text).map(this._stemmingFunction);\n  };\n\n  return StemmingTokenizer;\n}();\n\n/**\n * Stop words list copied from Lunr JS.\n */\nvar StopWordsMap = {\n  a: true,\n  able: true,\n  about: true,\n  across: true,\n  after: true,\n  all: true,\n  almost: true,\n  also: true,\n  am: true,\n  among: true,\n  an: true,\n  and: true,\n  any: true,\n  are: true,\n  as: true,\n  at: true,\n  be: true,\n  because: true,\n  been: true,\n  but: true,\n  by: true,\n  can: true,\n  cannot: true,\n  could: true,\n  dear: true,\n  did: true,\n  'do': true,\n  does: true,\n  either: true,\n  'else': true,\n  ever: true,\n  every: true,\n  'for': true,\n  from: true,\n  'get': true,\n  got: true,\n  had: true,\n  has: true,\n  have: true,\n  he: true,\n  her: true,\n  hers: true,\n  him: true,\n  his: true,\n  how: true,\n  however: true,\n  i: true,\n  'if': true,\n  'in': true,\n  into: true,\n  is: true,\n  it: true,\n  its: true,\n  just: true,\n  least: true,\n  \"let\": true,\n  like: true,\n  likely: true,\n  may: true,\n  me: true,\n  might: true,\n  most: true,\n  must: true,\n  my: true,\n  neither: true,\n  no: true,\n  nor: true,\n  not: true,\n  of: true,\n  off: true,\n  often: true,\n  on: true,\n  only: true,\n  or: true,\n  other: true,\n  our: true,\n  own: true,\n  rather: true,\n  said: true,\n  say: true,\n  says: true,\n  she: true,\n  should: true,\n  since: true,\n  so: true,\n  some: true,\n  than: true,\n  that: true,\n  the: true,\n  their: true,\n  them: true,\n  then: true,\n  there: true,\n  these: true,\n  they: true,\n  'this': true,\n  tis: true,\n  to: true,\n  too: true,\n  twas: true,\n  us: true,\n  wants: true,\n  was: true,\n  we: true,\n  were: true,\n  what: true,\n  when: true,\n  where: true,\n  which: true,\n  'while': true,\n  who: true,\n  whom: true,\n  why: true,\n  will: true,\n  'with': true,\n  would: true,\n  yet: true,\n  you: true,\n  your: true\n}; // Prevent false positives for inherited properties\n\nStopWordsMap.constructor = false;\nStopWordsMap.hasOwnProperty = false;\nStopWordsMap.isPrototypeOf = false;\nStopWordsMap.propertyIsEnumerable = false;\nStopWordsMap.toLocaleString = false;\nStopWordsMap.toString = false;\nStopWordsMap.valueOf = false;\n\n/**\n * Stop words are very common (e.g. \"a\", \"and\", \"the\") and are often not semantically meaningful in the context of a\n * search. This tokenizer removes stop words from a set of tokens before passing the remaining tokens along for\n * indexing or searching purposes.\n */\n\nvar StopWordsTokenizer = /*#__PURE__*/function () {\n  /**\n   * Constructor.\n   *\n   * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n   */\n  function StopWordsTokenizer(decoratedTokenizer) {\n    this._tokenizer = decoratedTokenizer;\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = StopWordsTokenizer.prototype;\n\n  _proto.tokenize = function tokenize(text) {\n    return this._tokenizer.tokenize(text).filter(function (token) {\n      return !StopWordsMap[token];\n    });\n  };\n\n  return StopWordsTokenizer;\n}();\n\nfunction _defineProperties(target, props) {\n  for (var i = 0; i < props.length; i++) {\n    var descriptor = props[i];\n    descriptor.enumerable = descriptor.enumerable || false;\n    descriptor.configurable = true;\n    if (\"value\" in descriptor) descriptor.writable = true;\n    Object.defineProperty(target, descriptor.key, descriptor);\n  }\n}\n\nfunction _createClass(Constructor, protoProps, staticProps) {\n  if (protoProps) _defineProperties(Constructor.prototype, protoProps);\n  if (staticProps) _defineProperties(Constructor, staticProps);\n  return Constructor;\n}\n\n/**\n * Simple client-side searching within a set of documents.\n *\n * <p>Documents can be searched by any number of fields. Indexing and search strategies are highly customizable.\n */\nvar Search = /*#__PURE__*/function () {\n  /**\n   * Array containing either a property name or a path (list of property names) to a nested value\n   */\n\n  /**\n   * Constructor.\n   * @param uidFieldName Field containing values that uniquely identify search documents; this field's values are used\n   *                     to ensure that a search result set does not contain duplicate objects.\n   */\n  function Search(uidFieldName) {\n    if (!uidFieldName) {\n      throw Error('js-search requires a uid field name constructor parameter');\n    }\n\n    this._uidFieldName = uidFieldName; // Set default/recommended strategies\n\n    this._indexStrategy = new PrefixIndexStrategy();\n    this._searchIndex = new TfIdfSearchIndex(uidFieldName);\n    this._sanitizer = new LowerCaseSanitizer();\n    this._tokenizer = new SimpleTokenizer();\n    this._documents = [];\n    this._searchableFields = [];\n  }\n  /**\n   * Override the default index strategy.\n   * @param value Custom index strategy\n   * @throws Error if documents have already been indexed by this search instance\n   */\n\n\n  var _proto = Search.prototype;\n\n  /**\n   * Add a searchable document to the index. Document will automatically be indexed for search.\n   * @param document\n   */\n  _proto.addDocument = function addDocument(document) {\n    this.addDocuments([document]);\n  }\n  /**\n   * Adds searchable documents to the index. Documents will automatically be indexed for search.\n   * @param document\n   */\n  ;\n\n  _proto.addDocuments = function addDocuments(documents) {\n    this._documents = this._documents.concat(documents);\n    this.indexDocuments_(documents, this._searchableFields);\n  }\n  /**\n   * Add a new searchable field to the index. Existing documents will automatically be indexed using this new field.\n   *\n   * @param field Searchable field or field path. Pass a string to index a top-level field and an array of strings for nested fields.\n   */\n  ;\n\n  _proto.addIndex = function addIndex(field) {\n    this._searchableFields.push(field);\n\n    this.indexDocuments_(this._documents, [field]);\n  }\n  /**\n   * Search all documents for ones matching the specified query text.\n   * @param query\n   * @returns {Array<Object>}\n   */\n  ;\n\n  _proto.search = function search(query) {\n    var tokens = this._tokenizer.tokenize(this._sanitizer.sanitize(query));\n\n    return this._searchIndex.search(tokens, this._documents);\n  }\n  /**\n   * @param documents\n   * @param _searchableFields Array containing property names and paths (lists of property names) to nested values\n   * @private\n   */\n  ;\n\n  _proto.indexDocuments_ = function indexDocuments_(documents, _searchableFields) {\n    this._initialized = true;\n    var indexStrategy = this._indexStrategy;\n    var sanitizer = this._sanitizer;\n    var searchIndex = this._searchIndex;\n    var tokenizer = this._tokenizer;\n    var uidFieldName = this._uidFieldName;\n\n    for (var di = 0, numDocuments = documents.length; di < numDocuments; di++) {\n      var doc = documents[di];\n      var uid;\n\n      if (uidFieldName instanceof Array) {\n        uid = getNestedFieldValue(doc, uidFieldName);\n      } else {\n        uid = doc[uidFieldName];\n      }\n\n      for (var sfi = 0, numSearchableFields = _searchableFields.length; sfi < numSearchableFields; sfi++) {\n        var fieldValue;\n        var searchableField = _searchableFields[sfi];\n\n        if (searchableField instanceof Array) {\n          fieldValue = getNestedFieldValue(doc, searchableField);\n        } else {\n          fieldValue = doc[searchableField];\n        }\n\n        if (fieldValue != null && typeof fieldValue !== 'string' && fieldValue.toString) {\n          fieldValue = fieldValue.toString();\n        }\n\n        if (typeof fieldValue === 'string') {\n          var fieldTokens = tokenizer.tokenize(sanitizer.sanitize(fieldValue));\n\n          for (var fti = 0, numFieldValues = fieldTokens.length; fti < numFieldValues; fti++) {\n            var fieldToken = fieldTokens[fti];\n            var expandedTokens = indexStrategy.expandToken(fieldToken);\n\n            for (var eti = 0, nummExpandedTokens = expandedTokens.length; eti < nummExpandedTokens; eti++) {\n              var expandedToken = expandedTokens[eti];\n              searchIndex.indexDocument(expandedToken, uid, doc);\n            }\n          }\n        }\n      }\n    }\n  };\n\n  _createClass(Search, [{\n    key: \"indexStrategy\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('IIndexStrategy cannot be set after initialization');\n      }\n\n      this._indexStrategy = value;\n    },\n    get: function get() {\n      return this._indexStrategy;\n    }\n    /**\n     * Override the default text sanitizing strategy.\n     * @param value Custom text sanitizing strategy\n     * @throws Error if documents have already been indexed by this search instance\n     */\n\n  }, {\n    key: \"sanitizer\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('ISanitizer cannot be set after initialization');\n      }\n\n      this._sanitizer = value;\n    },\n    get: function get() {\n      return this._sanitizer;\n    }\n    /**\n     * Override the default search index strategy.\n     * @param value Custom search index strategy\n     * @throws Error if documents have already been indexed\n     */\n\n  }, {\n    key: \"searchIndex\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('ISearchIndex cannot be set after initialization');\n      }\n\n      this._searchIndex = value;\n    },\n    get: function get() {\n      return this._searchIndex;\n    }\n    /**\n     * Override the default text tokenizing strategy.\n     * @param value Custom text tokenizing strategy\n     * @throws Error if documents have already been indexed by this search instance\n     */\n\n  }, {\n    key: \"tokenizer\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('ITokenizer cannot be set after initialization');\n      }\n\n      this._tokenizer = value;\n    },\n    get: function get() {\n      return this._tokenizer;\n    }\n  }]);\n\n  return Search;\n}();\n\n/**\n * This utility highlights the occurrences of tokens within a string of text. It can be used to give visual indicators\n * of match criteria within searchable fields.\n *\n * <p>For performance purposes this highlighter only works with full-word or prefix token indexes.\n */\nvar TokenHighlighter = /*#__PURE__*/function () {\n  /**\n   * Constructor.\n   *\n   * @param opt_indexStrategy Index strategy used by Search\n   * @param opt_sanitizer Sanitizer used by Search\n   * @param opt_wrapperTagName Optional wrapper tag name; defaults to 'mark' (e.g. <mark>)\n   */\n  function TokenHighlighter(opt_indexStrategy, opt_sanitizer, opt_wrapperTagName) {\n    this._indexStrategy = opt_indexStrategy || new PrefixIndexStrategy();\n    this._sanitizer = opt_sanitizer || new LowerCaseSanitizer();\n    this._wrapperTagName = opt_wrapperTagName || 'mark';\n  }\n  /**\n   * Highlights token occurrences within a string by wrapping them with a DOM element.\n   *\n   * @param text e.g. \"john wayne\"\n   * @param tokens e.g. [\"wa\"]\n   * @returns {string} e.g. \"john <mark>wa</mark>yne\"\n   */\n\n\n  var _proto = TokenHighlighter.prototype;\n\n  _proto.highlight = function highlight(text, tokens) {\n    var tagsLength = this._wrapText('').length;\n\n    var tokenDictionary = Object.create(null); // Create a token map for easier lookup below.\n\n    for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n      var token = this._sanitizer.sanitize(tokens[i]);\n\n      var expandedTokens = this._indexStrategy.expandToken(token);\n\n      for (var j = 0, numExpandedTokens = expandedTokens.length; j < numExpandedTokens; j++) {\n        var expandedToken = expandedTokens[j];\n\n        if (!tokenDictionary[expandedToken]) {\n          tokenDictionary[expandedToken] = [token];\n        } else {\n          tokenDictionary[expandedToken].push(token);\n        }\n      }\n    } // Track actualCurrentWord and sanitizedCurrentWord separately in case we encounter nested tags.\n\n\n    var actualCurrentWord = '';\n    var sanitizedCurrentWord = '';\n    var currentWordStartIndex = 0; // Note this assumes either prefix or full word matching.\n\n    for (var i = 0, textLength = text.length; i < textLength; i++) {\n      var character = text.charAt(i);\n\n      if (character === ' ') {\n        actualCurrentWord = '';\n        sanitizedCurrentWord = '';\n        currentWordStartIndex = i + 1;\n      } else {\n        actualCurrentWord += character;\n        sanitizedCurrentWord += this._sanitizer.sanitize(character);\n      }\n\n      if (tokenDictionary[sanitizedCurrentWord] && tokenDictionary[sanitizedCurrentWord].indexOf(sanitizedCurrentWord) >= 0) {\n        actualCurrentWord = this._wrapText(actualCurrentWord);\n        text = text.substring(0, currentWordStartIndex) + actualCurrentWord + text.substring(i + 1);\n        i += tagsLength;\n        textLength += tagsLength;\n      }\n    }\n\n    return text;\n  }\n  /**\n   * @param text to wrap\n   * @returns Text wrapped by wrapper tag (e.g. \"foo\" becomes \"<mark>foo</mark>\")\n   * @private\n   */\n  ;\n\n  _proto._wrapText = function _wrapText(text) {\n    var tagName = this._wrapperTagName;\n    return \"<\" + tagName + \">\" + text + \"</\" + tagName + \">\";\n  };\n\n  return TokenHighlighter;\n}();\n\nexport { AllSubstringsIndexStrategy, CaseSensitiveSanitizer, ExactWordIndexStrategy, LowerCaseSanitizer, PrefixIndexStrategy, Search, SimpleTokenizer, StemmingTokenizer, StopWordsMap, StopWordsTokenizer, TfIdfSearchIndex, TokenHighlighter, UnorderedSearchIndex };\n","import { useCallback, useMemo } from 'react'\nimport { Typography } from 'mui-custom'\nimport { css } from '@emotion/react'\nimport { PageProps, graphql } from 'gatsby'\nimport { PostList } from '@/components/common/post-list'\nimport useIntersectionObserver from '@/hooks/useIntersectionObserver'\nimport useRenderedCount from '@/hooks/useRenderedCount'\nimport * as Dom from '@/utils/dom'\nimport useScrollEvent from '@/hooks/useScrollEvent'\nimport { toFit } from '@/utils/event-manager'\nimport useUrlParamsPost from '@/hooks/useUrlParamsPost'\nimport { useSelectPosts } from '@/hooks/useQueryPost'\nimport { BASE_LINE } from '@/constants'\n\ninterface SearchPageDataProps {\n  site: {\n    siteMetadata: {\n      configs: {\n        countOfInitialPost: number\n      }\n    }\n  }\n}\n\nconst SearchPage = ({\n  data: {\n    site: {\n      siteMetadata: {\n        configs: { countOfInitialPost },\n      },\n    },\n  },\n}: PageProps<SearchPageDataProps>) => {\n  const { params } = useUrlParamsPost()\n  const { data } = useSelectPosts()\n  const [count, countRef, increaseCount] = useRenderedCount()\n\n  const getDistance = useCallback((currentPos: number) => {\n    return Dom.getDocumentHeight() - currentPos\n  }, [])\n\n  useIntersectionObserver()\n\n  useScrollEvent(() => {\n    const currentPos = window.scrollY + window.innerHeight\n    const isTriggerPos = () => getDistance(currentPos) < BASE_LINE\n    const doesNeedMore = () => data.length > countRef.current * countOfInitialPost\n\n    return toFit(increaseCount, {\n      dismissCondition: () => !isTriggerPos(),\n      triggerCondition: () => isTriggerPos() && doesNeedMore(),\n    })()\n  })\n\n  const refinedPosts = useMemo(() => {\n    return data.slice(0, count * countOfInitialPost)\n  }, [data, count, countOfInitialPost])\n\n  return (\n    <div>\n      <Typography\n        variant=\"title2\"\n        css={css`\n          display: block;\n          margin: 50px 0;\n          text-align: center;\n        `}\n      >\n        {data.length > 0\n          ? `\"${params.keyword}\" 에 대해 총 ${data.length}건이 검색되었습니다.`\n          : `\"${params.keyword}\" 에 대한 검색 결과가 없습니다.`}\n      </Typography>\n      <PostList posts={refinedPosts} />\n    </div>\n  )\n}\n\nexport const pageQuery = graphql`\n  query {\n    site {\n      siteMetadata {\n        configs {\n          countOfInitialPost\n        }\n      }\n    }\n  }\n`\n\nexport default SearchPage\n","import { Search } from 'js-search'\nimport { useStaticQuery, graphql } from 'gatsby'\nimport { useEffect, useMemo, useState } from 'react'\nimport useUrlParamsPost from './useUrlParamsPost'\n\ninterface Node {\n  excerpt: string\n  id: string\n  frontmatter: {\n    title: string\n  }\n  fields: {\n    slug: string\n  }\n  html: string\n}\n\nexport const useSelectPosts = () => {\n  const { params } = useUrlParamsPost()\n  const [searchResult, setSearchResult] = useState<any>([])\n  const { allMarkdownRemark } = useStaticQuery(graphql`\n    query SearchQuery {\n      allMarkdownRemark(sort: { order: DESC, fields: frontmatter___date }) {\n        edges {\n          node {\n            excerpt(pruneLength: 280, truncate: true)\n            id\n            frontmatter {\n              title\n            }\n            fields {\n              slug\n            }\n            html\n          }\n        }\n      }\n    }\n  `)\n\n  const documents = useMemo(\n    () =>\n      allMarkdownRemark.edges.map(({ node }: { node: Node }) => ({\n        id: node.id,\n        title: node.frontmatter.title,\n        excerpt: node.excerpt,\n        slug: node.fields.slug,\n        content: node.html.replace(/(<([^>]+)>)/gi, ''), // Remove HTML tags from content\n      })),\n    [allMarkdownRemark.edges],\n  )\n\n  const jsSearch = useMemo(() => new Search('id'), [])\n\n  jsSearch.addIndex('title')\n  jsSearch.addIndex('excerpt')\n  jsSearch.addIndex('content')\n  jsSearch.addDocuments(documents)\n\n  useEffect(() => {\n    if (params.keyword) {\n      const result = jsSearch.search(params.keyword)\n      setSearchResult(result)\n      return\n    }\n    setSearchResult([])\n  }, [jsSearch, params.keyword])\n\n  return { data: searchResult }\n}\n","export const toFit = (\n  cb: Function,\n  { dismissCondition = () => false, triggerCondition = () => true },\n) => {\n  if (!cb) {\n    throw Error('Invalid required arguments')\n  }\n\n  let tick = false\n\n  return () => {\n    if (tick) {\n      return null\n    }\n\n    tick = true\n    return requestAnimationFrame(() => {\n      if (dismissCondition()) {\n        tick = false\n        return null\n      }\n\n      if (triggerCondition()) {\n        tick = false\n        return cb()\n      }\n      return null\n    })\n  }\n}\n"],"names":["isEmpty","storage","Object","keys","length","getValueFrom","key","rawData","getItem","JSON","parse","setValueTo","data","setItem","stringify","localStorage","window","undefined","sessionStorage","setValueToSessionStorage","partial","getValueFromSessionStorage","SESSION_STORAGE_KEY","useRenderedCount","initialCount","defaultValue","count","setCount","useState","countRef","useRef","increaseCount","useCallback","prev","useEffect","current","onScroll","addEventListener","passive","removeEventListener","PrefixIndexStrategy","prototype","expandToken","token","expandedTokens","string","i","charAt","push","LowerCaseSanitizer","sanitize","text","toLocaleLowerCase","trim","getNestedFieldValue","object","path","value","TfIdfSearchIndex","uidFieldName","this","_uidFieldName","_tokenToIdfCache","_tokenMap","_proto","indexDocument","uid","doc","tokenDatum","tokenMap","$numDocumentOccurrences","$totalNumOccurrences","$uidMap","uidMap","$document","$numTokenOccurrences","search","tokens","corpus","uidToDocumentMap","numTokens","tokenMetadata","j","numKeys","documents","calculateTfIdf","_createCalculateTfIdf","sort","documentA","documentB","_createCalculateIdf","tokenToIdfCache","numDocumentsWithToken","Math","log","calculateIdf","document","score","inverseDocumentFrequency","Infinity","Array","REGEX","SimpleTokenizer","tokenize","split","filter","_defineProperties","target","props","descriptor","enumerable","configurable","writable","defineProperty","Search","Error","_indexStrategy","_searchIndex","_sanitizer","_tokenizer","_documents","_searchableFields","Constructor","protoProps","staticProps","addDocument","addDocuments","concat","indexDocuments_","addIndex","field","query","_initialized","indexStrategy","sanitizer","searchIndex","tokenizer","di","numDocuments","sfi","numSearchableFields","fieldValue","searchableField","toString","fieldTokens","fti","numFieldValues","fieldToken","eti","nummExpandedTokens","expandedToken","set","get","_ref","name","styles","_ref2","site","siteMetadata","configs","countOfInitialPost","params","useUrlParamsPost","useSelectPosts","searchResult","setSearchResult","allMarkdownRemark","useStaticQuery","useMemo","edges","map","node","id","title","frontmatter","excerpt","slug","fields","content","html","replace","jsSearch","keyword","result","getDistance","currentPos","Dom","useIntersectionObserver","useScrollEvent","scrollY","innerHeight","isTriggerPos","BASE_LINE","toFit","dismissCondition","triggerCondition","refinedPosts","slice","_jsxs","children","_jsx","Typography","variant","css","PostList","posts","cb","tick","requestAnimationFrame"],"sourceRoot":""}